// ----------------- header declaration ----------------- 
init_code(includes) ::= <<
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
import org.apache.spark.rdd._
import dbis.pig.backends.spark._

<\n>
>>

// ----------------- schema class -----------------
schema_class(name, fields, string_rep) ::= <<
case class <name> (<fields>) extends java.io.Serializable with SchemaClass {
override def mkString(_c: String = ",") = <string_rep>
}

>>

// ----------------- BEGIN of code building and initializing the query --------
query_object(name, embedded_code) ::= <<
object <name> {
    <embedded_code>

>>

// ----------------- BEGIN of code building and initializing the query --------
begin_query(name) ::= <<
    def main(args: Array[String]) {
        val conf = new SparkConf().setAppName("<name>_App")
        val sc = new SparkContext(conf)

>>

// ----------------- LOAD text file -------------------------------------------
loader(out, file, class, func, extractor, params) ::= <<
        val <out> = <func>[<class>]().load(sc, "<file>", <extractor><if (params)>, <params><endif>)
>>

// ------------------ DUMP results --------------------------------------------
dump(in) ::=<<
        <in>.collect.map(t => println(t.mkString()))
>>

// ------------------ STORE Results on disk -----------------------------------

store(in, file, class, func, params) ::= <<
    val <in>_helper = <in>.coalesce(1, true)
    <func>[<class>]().write("<file>", <in>_helper<if (params)>, <params><endif>)
>>

// ------------------ FILTER for a predicate ----------------------------------
filter(out,in,pred) ::=<<
        val <out> = <in>.filter(t => {<pred>})
>>

// ------------------ Executes an expression FOREACH input element -----------
foreach(out, in, expr, class) ::=<<
        val <out> = <in>.map(t => <class>(<expr>))
>>

// ------------------ Executes an expression FOREACH input element requiring a flatMap -----------
foreachFlatMap(out,in,expr) ::=<<
        val <out> = <in>.flatMap(t => <expr>).map(t => List(t))
>>

// ------------------ GROUPs elements on an expression ------------------------
groupBy(out, in, expr, class, keyExtr) ::=<<
<if (expr)>
        val <out> = <in>.groupBy(t => {<expr>}).map{case (k,v) => <class>(<keyExtr>,v)}
<else>
        val <out> = <in>.coalesce(1).glom.map(t => <class>("all", t))
<endif>
>>

// ------------------ Outputs only distinct values ----------------------------
distinct(out, in) ::=<<
        val <out> = <in>.distinct
>>

// ------------------ Outputs only num records --------------------------------
limit(out, in, num) ::=<<
        val <out> = sc.parallelize(<in>.take(<num>))
>>

// ------------------ Joins two streams on the specified keys -----------------
join_key_map(rels, keys) ::=<<
        <rels,keys:{ rel,key |val <rel>_kv = <rel>.map(t => (<key>,t))
        }>
>>

join(out, class, rel1, key1, rel2, key2, fields) ::=<<
        val <out> = <rel1>_kv<rel2:{ rel |.join(<rel>_kv).map{case (k,(v,w)) => <class>(<fields>)\}}>

>>

// ------------------ UNIONs multiple streams to one --------------------------
union(out,in,others) ::=<<
        val <out> = <in><others:{ e | .union(<e>)}>
>>

// ------------------ Returns a SAMPLE of the data ----------------------------
sample(out,in,expr) ::=<<
        val <out> = <in>.sample(false, <expr>)
>>

// ------------------ ORDERs the input BY a key -------------------------------
orderBy(out, in, key, asc) ::=<<
        val <out> = <in>.keyBy(t => <key>).sortByKey(<asc>).map{case (k,v) => v}
>>

orderHelper(params) ::=<<
    case class <params.cname>(<params.fields>) extends Ordered[<params.cname>] {
        def compare(that: <params.cname>) = <params.cmpExpr>
    }
>>

// ------------------ STREAM operators ----------------------------------------
streamOp(out,in,op,params) ::=<<
        val <out> = <op>(sc, <in><params>)
>>

// ----------------------- FS commands ----------------------------------------
fs(cmd,params) ::=<<
    HDFSService.process(<cmd>, <params>)
>>

// ------------------ RSCRIPT operators ----------------------------------------
rscript(out,in,script) ::=<<
        val <out> = RScriptOp.process(sc, <in>, <script>, "res")
>>

// ----------------- END of the code implementing the query -------------------
end_query(name) ::= <<
    
        sc.stop()
    }
}
>>
