#!/bin/sh

echo '
 ____  _         _          ____                   _
|  _ \(_) __ _  | |_ ___   / ___| _ __   __ _ _ __| | __
| |_) | |/ _` | | __/ _ \  \___ \|  _ \ / _` |  __| |/ /
|  __/| | (_| | | || (_) |  ___) | |_) | (_| | |  |   <
|_|   |_|\__, |  \__\___/  |____/| .__/ \__,_|_|  |_|\_\
         |___/                   |_|
'
# TODO: we should find our jar file the same way we do for spark
PIG_LIB=`dirname $0`/../target/scala-2.11/PigCompiler.jar

# the directory to include in classpath to enable backends
# this should actually be set by the user using external variables
BACKEND_DIR=`dirname $0`/../sparklib/target/scala-2.11/*

if [ -z "$BACKEND_DIR" ]; then # if BACKEND_DIR does not exist, use our default one
    BACKEND_DIR=`dirname $0`/../backends/*
else
    if [[ "$BACKEND_DIR" == */ ]]; then # if it ends with / it's a directory - include all files using the wildcard *
        BACKEND_DIR=$BACKEND_DIR*
    elif [[ "$BACKEND_DIR" != */\* && "$BACKEND_DIR" != *.jar ]]; then  #if it ends not with / or .jar we assume it's a dir - append /*
        BACKEND_DIR=$BACKEND_DIR/*
    fi
fi

echo "Including backends in $BACKEND_DIR"

CP=$PIG_LIB:$BACKEND_DIR
if [ -z "$SPARK_JAR" ]; then
    echo "Please set SPARK_JAR to your spark-assembly-hadoop jar file"
    exit 1
else
    CP=$SPARK_JAR:$CP
fi

#CP=/Users/kai/Projects/spark-1.3.1/core/target/spark-core_2.11-1.3.1.jar:$PIG_LIB

java -Dscala.usejavacp=true -cp $CP dbis.pig.PigCompiler $*
