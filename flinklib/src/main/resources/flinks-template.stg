// ----------------- header declaration ----------------- 
init_code(additional_imports) ::= <<
import org.apache.flink.streaming.api.scala._
import dbis.pig.backends.flink._
import dbis.pig.backends.flink.streaming._
import java.util.concurrent.TimeUnit
import org.apache.flink.util.Collector
import dbis.pig.backends.{SchemaClass, Record}
<if (additional_imports)>
<additional_imports>
<endif>

<\n>
>>

// ----------------- schema class -----------------
schema_class(name, fields, string_rep) ::= <<
case class <name> (<fields>) extends java.io.Serializable with SchemaClass {
override def mkString(_c: String = ",") = <string_rep>
}

>>

// ----------------- BEGIN of code building and initializing the query --------
query_object(name, embedded_code) ::= <<
object <name> {
  <embedded_code>
>>

// ----------------- BEGIN of code building and initializing the query --------
begin_query(name, profiling) ::= <<<\n>
  def main(args: Array[String]) {
    val env = StreamExecutionEnvironment.getExecutionEnvironment<\n>
>>

// ----------------- LOAD text file -------------------------------------------
loader(out, file, class, func, extractor, params) ::=<<
    val <out> = <func>[<class>]().loadStream(env, "<file>", <extractor><if (params)>, <params><endif>)
>>

// ------------------ DUMP Results --------------------------------------------
dump(in) ::=<<
    <in>.map(_.mkString()).print
>>

// ------------------ STORE Results on Disk -----------------------------------
store(in, file, class, func, schema, params) ::=<<
    /*
    <if (schema)>
        val <in>_storehelper = <in>.map(t => <schema>)
    <else>
        val <in>_storehelper = <in>
    <endif>
    */
    //val <in>_helper = <in>.setParallelism(1)
    <func>[<class>]().writeStream("<file>", <in><if (params)>, <params><endif>)
>>

// ------------------ FILTER for a Predicate ----------------------------------
filter(out,in,pred,windowMode, class) ::=<<
<if (windowMode)>
    val <out> = <in>.mapWindow(custom<out>Filter _)
<else>
    val <out> = <in>.filter(t => {<pred>})
<endif>
>>

filterHelper(params) ::=<<
    def custom<params.out>Filter(ts: Iterable[<params.class>], out: Collector[<params.class>]) ={
      ts.filter(t => {<params.pred>}).foreach(x => out.collect(x))
    }
>>

// ------------------ SPLIT input INTO multiple outputs -----------------------
splitInto(in,out,pred) ::=<<
<out,pred:{ o,p |<\\>
    val <o> = <in>.filter(t => {<p>\})
}>
>>


// ------------------ Executes an expression FOREACH input element ------------
foreach(out,in,expr,aggrs,windowMode, class) ::=<<
<if(windowMode)>
    val <out> = <in>.mapWindow(custom<out>Map _)
<else>
    <if (aggrs)>
    val <out> = <in>.mapWithState(PigFuncs.streamFunc(<aggrs>)).map(t => <expr>)
    <else>
    val <out> = <in>.map(t => <class>(<expr>))
    <endif>
<endif>
>>

foreachHelper(params) ::=<<
<if(params.windowMode)>
    def custom<params.out>Map(ts: Iterable[<params.class>], out: Collector[<params.class>]) = {
      ts.foreach { t => out.collect(<params.class>(<params.expr>))}
    }
<else>    
<endif>
>>

// ----- Executes an expression FOREACH input element requiring a flatMap -----
foreachFlatMap(out,in,expr,windowMode) ::=<<
    val <out> = <in>.flatMap(t => <expr>).map(t => List(t))
>>

// ------------------ GROUPS elements on an expression ------------------------
groupBy(out,in,expr,windowMode, class) ::=<<
<if (expr)>
  <if(windowMode)>
    val <out> = <in>.mapWindow(custom<out>Map _).groupBy(t => t._0)
  <else>
    val <out> = <in>.map(t => <class>((<expr>),List(t))).groupBy(t => t._0)
  <endif>
<else>
    val <out> = <in>.map(t => List("all", List(t))).groupBy(t => t._0)
<endif>
>>

groupByHelper(params) ::=<<
    def custom<params.out>Map(ts: Iterable[<params.class>], out: Collector[<params.class>]) = {
<!      out.collect(ts.groupBy(t => <params.expr>).flatMap(x => List(x._1,x._2)).toList) !>
      ts.groupBy(t => <params.expr>).foreach(t => out.collect(<params.class>(t._1,t._2)))
    }
>>

// ------------------ Outputs only distinct values ----------------------------
distinct(out,in, class) ::=<<
    val <out> = <in>.mapWindow(distinct _)
>>

distinctHelper(params) ::=<<
    def distinct(ts: Iterable[<params.class>], out: Collector[<params.class>]) ={
      ts.toList.distinct.foreach{ x => out.collect(x) }
    }
>>

// ------------------ ORDERs the input BY a key -------------------------------
orderBy(out,in,key,asc) ::=<<
    val <out> = <in>.mapWindow(custom<out>Order _)
>>

orderHelper(params) ::=<<
    def custom<params.out>Order(ts: Iterable[List[Any]], out: Collector[List[Any]]) ={
      ts.toList.asInstanceOf[List[List[String]]].sortBy(t => (<params.key>))<if (params.reverse)>(Ordering[String].reverse)<endif>.foreach { x => out.collect(x) }
    }
>>

// ------------------ Passes Stream through a Window Operator -----------------
window(out,in,window,wUnit,slider,sUnit) ::=<<
<if (wUnit)>
  <if (sUnit)>
    val <out> = <in>.window(Time.of(<window>, TimeUnit.<wUnit>)).every(Time.of(<slider>, TimeUnit.<sUnit>))
  <else>
    val <out> = <in>.window(Time.of(<window>, TimeUnit.<wUnit>)).every(Count.of(<slider>))
  <endif>
<else>
  <if (sUnit)>
    val <out> = <in>.window(Count.of(<window>)).every(Time.of(<slider>, TimeUnit.<sUnit>))
  <else>
    val <out> = <in>.window(Count.of(<window>)).every(Count.of(<slider>))
  <endif>
<endif>
>>

// --------- Transform Windows back to continuous Stream ----------------------
windowFlatten(out,in) ::=<<
    val <out> = <in>.flatten
>>

// ------------------ Joins two or more streams on the specified keys ---------
join_key_map(rels,keys) ::=<<
>>

join(out,rel1,key1,rel2,key2,window,wUnit) ::=<<
    val <out> = <rel1><rel2,key2:{ r,k |<\\>
    .join(<r>).onWindow(<window>, TimeUnit.<wUnit>).where(t => <key1>).equalTo(t => <k>)<\\>
    .map{ t => t._1 ++ t._2 \}<\\>
    }>
>>

// ------------ Computes the CROSS product of two or more relations -----------
cross(out,rel1,rel2,window,wUnit) ::=<<
    val <out> = <rel1><rel2:{ r |<\\>
    .cross(<r>).onWindow(<window>, TimeUnit.<wUnit>).map{ t => t._1 ++ t._2 \}<\\>
    }>
>>

// ------------------ UNIONs multiple streams to one --------------------------
union(out,in,others) ::=<<
    val <out> = <in><others:{ e | .union(<e>)}>
>>

// ------------------ Outputs only a SAMPLE of the data -----------------------
sample(out,in,expr) ::=<<
    val <out> = <in>.filter(t => util.Random.nextDouble \<= <expr>)
>>

// ------------------ STREAM operators ----------------------------------------
streamOp(out,in,op,params) ::=<<
    val <out> = <op>(env, <in><params>)
>>

// ------------------ Reads from a SOCKET -------------------------------------
socketRead(out,addr,mode,func,params) ::=<<
<if (mode)>
    val <out> = <func>().zmqSubscribe(env, "<addr.protocol><addr.hostname>:<addr.port>"<params>)
<else>
    val <out> = <func>().connect(env, "<addr.hostname>", <addr.port><params>)
<endif>
>>

// ------------------ Writes to a SOCKET -------------------------------------
socketWrite(in,addr,mode,func) ::=<<
<if (mode)>
    <func>().zmqPublish("<addr.protocol><addr.hostname>:<addr.port>", <in>)
<else>
    <func>().bind("<addr.hostname>", <addr.port>, <in>)
<endif>
>>

// ----------------- END of the code implementing the query -------------------
end_query(name, hook) ::= <<
    env.execute("<name>")
    
<if (hook)>
	shutdownHook()
<endif>
  }
}
>>
